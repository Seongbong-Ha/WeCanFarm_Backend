# app/utils/image_handler.py
import base64
import os
import numpy as np
from io import BytesIO
from PIL import Image, ImageDraw, ImageFont
from typing import List, Tuple, Dict

# YOLO ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ (í•œ ë²ˆë§Œ ë¡œë“œ)
_yolo_model = None

def load_yolo_model():
    """YOLO Segmentation ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ì‹œ í•œ ë²ˆë§Œ)"""
    global _yolo_model
    if _yolo_model is None:
        try:
            from ultralytics import YOLO
            model_path = os.path.join(os.path.dirname(__file__), '../models/yolo_v1.pt')
            _yolo_model = YOLO(model_path)
            print("âœ… YOLO Segmentation ëª¨ë¸ ë¡œë”© ì„±ê³µ")
        except Exception as e:
            print(f"âŒ YOLO Segmentation ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            _yolo_model = None
    return _yolo_model

def decode_base64_to_image(base64_str: str) -> Image.Image:
    """base64 ë¬¸ìì—´ì„ PIL Imageë¡œ ë””ì½”ë”©"""
    # "data:image/jpeg;base64,..." ê°™ì€ ì ‘ë‘ì–´ ì œê±°
    if "," in base64_str:
        base64_str = base64_str.split(",")[1]
    image_data = base64.b64decode(base64_str)
    return Image.open(BytesIO(image_data))

def image_to_base64(image: Image.Image, format: str = "JPEG") -> str:
    """PIL Imageë¥¼ base64 ë¬¸ìì—´ë¡œ ì¸ì½”ë”©"""
    buffered = BytesIO()
    # PNGê°€ ì•„ë‹Œ ê²½ìš° RGBë¡œ ë³€í™˜ (JPEGëŠ” RGBA ì§€ì› ì•ˆí•¨)
    if format.upper() == "JPEG" and image.mode in ("RGBA", "P"):
        image = image.convert("RGB")
    image.save(buffered, format=format)
    encoded_string = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return encoded_string

def draw_bounding_boxes(image: Image.Image, detections: List[dict], font_size: int = 20) -> Image.Image:
    """ì´ë¯¸ì§€ì— ë°”ìš´ë”©ë°•ìŠ¤ì™€ ë¼ë²¨ì„ ê·¸ë¦¬ê¸°
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€
        detections: ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            [{"bbox": [x1, y1, x2, y2], "label": "ì§ˆë³‘ëª…", "confidence": 0.95, "crop_type": "pepper"}]
        font_size: í…ìŠ¤íŠ¸ í°íŠ¸ í¬ê¸°
    Returns:
        ë°”ìš´ë”©ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
    """
    # ì´ë¯¸ì§€ ë³µì‚¬ (ì›ë³¸ ë³´ì¡´)
    image_with_boxes = image.copy()
    draw = ImageDraw.Draw(image_with_boxes)
    
    # í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
    try:
        # macOSì˜ ê²½ìš°
        font_path = "/System/Library/Fonts/AppleSDGothicNeo.ttc"
        if os.path.exists(font_path):
            font = ImageFont.truetype(font_path, font_size)
        else:
            # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            font = ImageFont.load_default()
    except:
        font = ImageFont.load_default()
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ì‘ë¬¼/ì§ˆë³‘ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ)
    color_palette = {
        "ì •ìƒ": "#00FF00",          # ì´ˆë¡ìƒ‰
        "ê³ ì¶”ì ë¬´ëŠ¬ë³‘": "#FF0000",    # ë¹¨ê°„ìƒ‰
        "ê³ ì¶”ë§ˆì¼ë“œëª¨í‹€ë°”ì´ëŸ¬ìŠ¤": "#FF8800",  # ì£¼í™©ìƒ‰
        "default": "#0080FF"       # íŒŒë€ìƒ‰ (ê¸°ë³¸)
    }
    
    for detection in detections:
        bbox = detection.get("bbox", [])
        label = detection.get("label", "ì•Œ ìˆ˜ ì—†ìŒ")
        confidence = detection.get("confidence", 0.0)
        
        if len(bbox) != 4:
            continue
            
        x1, y1, x2, y2 = bbox
        
        # ë°”ìš´ë”©ë°•ìŠ¤ ìƒ‰ìƒ ì„ íƒ
        color = color_palette.get(label, color_palette["default"])
        
        # ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë‘ê»˜ 3í”½ì…€)
        for i in range(3):
            draw.rectangle([x1-i, y1-i, x2+i, y2+i], outline=color)
        
        # ë¼ë²¨ í…ìŠ¤íŠ¸ ìƒì„±
        text = f"{label} ({confidence:.2f})"
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ í¬ê¸° ê³„ì‚°
        bbox_text = draw.textbbox((0, 0), text, font=font)
        text_width = bbox_text[2] - bbox_text[0]
        text_height = bbox_text[3] - bbox_text[1]
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
        text_bg_coords = [x1, y1 - text_height - 4, x1 + text_width + 8, y1]
        draw.rectangle(text_bg_coords, fill=color)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (í°ìƒ‰)
        draw.text((x1 + 4, y1 - text_height - 2), text, fill="white", font=font)
    
    return image_with_boxes

def resize_image(image: Image.Image, max_size: Tuple[int, int] = (1024, 1024), 
                maintain_aspect: bool = True) -> Image.Image:
    """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€
        max_size: ìµœëŒ€ í¬ê¸° (width, height)
        maintain_aspect: ì¢…íš¡ë¹„ ìœ ì§€ ì—¬ë¶€
    Returns:
        í¬ê¸°ê°€ ì¡°ì •ëœ ì´ë¯¸ì§€
    """
    if maintain_aspect:
        image.thumbnail(max_size, Image.Resampling.LANCZOS)
        return image
    else:
        return image.resize(max_size, Image.Resampling.LANCZOS)

def validate_image(image: Image.Image) -> bool:
    """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬
    Args:
        image: ê²€ì‚¬í•  ì´ë¯¸ì§€
    Returns:
        ìœ íš¨í•œ ì´ë¯¸ì§€ì¸ì§€ ì—¬ë¶€
    """
    try:
        # ê¸°ë³¸ ê²€ì‚¬
        if image is None:
            return False
        
        # í¬ê¸° ê²€ì‚¬ (ìµœì†Œ 32x32)
        width, height = image.size
        if width < 32 or height < 32:
            return False
        
        # ìµœëŒ€ í¬ê¸° ê²€ì‚¬ (4096x4096)
        if width > 4096 or height > 4096:
            return False
        
        # ì´ë¯¸ì§€ ëª¨ë“œ ê²€ì‚¬
        if image.mode not in ["RGB", "RGBA", "L"]:
            return False
        
        return True
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
        return False

def prepare_image_for_model(image: Image.Image, target_size: Tuple[int, int] = (224, 224)) -> Image.Image:
    """ëª¨ë¸ ì…ë ¥ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€
        target_size: ëª©í‘œ í¬ê¸°
    Returns:
        ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
    """
    # RGBë¡œ ë³€í™˜
    if image.mode != "RGB":
        image = image.convert("RGB")
    
    # í¬ê¸° ì¡°ì •
    image = image.resize(target_size, Image.Resampling.LANCZOS)
    
    return image

def yolo_detection(image: Image.Image) -> List[dict]:
    """
    YOLO Segmentation ê°ì§€ ë©”ì¸ í•¨ìˆ˜
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
    Returns:
        ê°ì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)
    """
    try:
        # YOLO ëª¨ë¸ ë¡œë“œ
        model = load_yolo_model()
        if model is None:
            print("âŒ YOLO ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        # ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (YOLO ì…ë ¥ìš©)
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        print(f"ğŸ” YOLO Segmentation ì¶”ë¡  ì‹œì‘ - ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
        
        # YOLO Segmentation ì¶”ë¡  ì‹¤í–‰
        results = model(image, verbose=False)
        
        # ì›ë³¸ ê°ì§€ ê²°ê³¼ ìˆ˜ì§‘
        raw_detections = []
        image_width, image_height = image.size
        
        for result in results:
            boxes = result.boxes    # ë°”ìš´ë”©ë°•ìŠ¤ (Detection ê²°ê³¼)
            masks = result.masks    # ë§ˆìŠ¤í¬ (Segmentation ê²°ê³¼)
            
            if boxes is not None and len(boxes) > 0:
                print(f"ğŸ” ê°ì§€ëœ ê°ì²´ ìˆ˜: {len(boxes)}")
                
                for i, box in enumerate(boxes):
                    # ë°”ìš´ë”©ë°•ìŠ¤ ì¢Œí‘œ
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # ì‹ ë¢°ë„
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    # í´ë˜ìŠ¤
                    cls_id = int(box.cls[0].cpu().numpy())
                    
                    # ë§ˆìŠ¤í¬ ì •ë³´ (ì˜µì…˜)
                    mask_data = None
                    if masks is not None and i < len(masks):
                        mask_data = masks[i].data.cpu().numpy()
                    
                    detection = {
                        "bbox": [int(x1), int(y1), int(x2), int(y2)],
                        "crop_type": "pepper",
                        "confidence": confidence
                    }
                    raw_detections.append(detection)
            else:
                print("ğŸ” ê°ì§€ëœ ë°•ìŠ¤ê°€ ì—†ìŒ")
        
        # ê°„ë‹¨í•œ 3ë‹¨ê³„ í•„í„°ë§ (í•˜ë“œì½”ë”©)
        if raw_detections:
            # 1ë‹¨ê³„: ì‹ ë¢°ë„ í•„í„°ë§ (50% ì´ìƒ)
            confidence_filtered = []
            for detection in raw_detections:
                if detection["confidence"] >= 0.5:
                    confidence_filtered.append(detection)
                    print(f"ğŸ” 1ì°¨ í†µê³¼: ì‹ ë¢°ë„ {detection['confidence']:.2f}")
                else:
                    print(f"âŒ 1ì°¨ íƒˆë½: ì‹ ë¢°ë„ {detection['confidence']:.2f}")
            
            # 2ë‹¨ê³„: í¬ê¸° í•„í„°ë§ (0.5% ~ 80% ë²”ìœ„)
            size_filtered = []
            total_area = image_width * image_height
            
            for detection in confidence_filtered:
                bbox = detection["bbox"]
                x1, y1, x2, y2 = bbox
                bbox_area = (x2 - x1) * (y2 - y1)
                area_ratio = bbox_area / total_area
                
                # ìµœì†Œ í¬ê¸° < ë°•ìŠ¤ í¬ê¸° < ìµœëŒ€ í¬ê¸°
                if 0.005 <= area_ratio <= 1.0:  # 0.5% ~ 80%
                    size_filtered.append(detection)
                    print(f"ğŸ” 2ì°¨ í†µê³¼: í¬ê¸°ë¹„ìœ¨ {area_ratio:.3f}")
                elif area_ratio < 0.005:
                    print(f"âŒ 2ì°¨ íƒˆë½(ë„ˆë¬´ ì‘ìŒ): í¬ê¸°ë¹„ìœ¨ {area_ratio:.3f}")
                else:
                    print(f"âŒ 2ì°¨ íƒˆë½(ë„ˆë¬´ í¼): í¬ê¸°ë¹„ìœ¨ {area_ratio:.3f}")
            
            # 3ë‹¨ê³„: ì‹ ë¢°ë„ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 5ê°œ
            size_filtered.sort(key=lambda x: x["confidence"], reverse=True)
            filtered_detections = size_filtered[:5]
            
            print(f"ğŸ” 3ì°¨ ì™„ë£Œ: ìµœì¢… {len(filtered_detections)}ê°œ ì„ íƒ")
        else:
            filtered_detections = []
        
        if len(filtered_detections) == 0:
            print("ğŸ“ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"âœ… YOLO Segmentation ê°ì§€ ì™„ë£Œ: {len(filtered_detections)}ê°œ ê°ì²´")
        
        return filtered_detections
        
    except Exception as e:
        print(f"âŒ YOLO Segmentation ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return []